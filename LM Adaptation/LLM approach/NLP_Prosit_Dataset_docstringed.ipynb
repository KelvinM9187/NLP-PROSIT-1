{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4751cfd7",
   "metadata": {},
   "source": [
    "## Dataset Preparation (Afrimed-QA v2)\n",
    "\n",
    "This notebook loads **Afrimed-QA v2** from Hugging Face, inspects question types, filters to **MCQ** items,\n",
    "removes questions with **multiple correct answers**, and saves the processed dataset to Google Drive.\n",
    "\n",
    "> Tip: Run cells top-to-bottom. If you restart the runtime, remount Drive before saving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities and dependencies.\n",
    "\n",
    "- `datasets.load_dataset`: download/load Afrimed-QA v2.\n",
    "- `google.colab.userdata` / `huggingface_hub.login`: optional, for private datasets (not required for public datasets).\n",
    "\"\"\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login  # optional: for authenticated HF access\n",
    "from google.colab import userdata  # optional: to read HF token stored in Colab\n",
    "import math  # optional: kept for future use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ef6d0",
   "metadata": {},
   "source": [
    "### Load Afrimed-QA v2\n",
    "\n",
    "We load the dataset using `datasets.load_dataset`. The returned object is a `DatasetDict` with splits\n",
    "(i.e., `train`, `validation`, `test`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Afrimed-QA v2 from Hugging Face\n",
    "ds = load_dataset(\"intronhealth/afrimedqa_v2\")\n",
    "\n",
    "# Quick sanity check: show available splits and features\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b219ab",
   "metadata": {},
   "source": [
    "### Inspect question types\n",
    "\n",
    "Afrimed-QA contains multiple question formats. We list the unique `question_type` values\n",
    "so we can focus only on **MCQ** questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique question types present in the training split\n",
    "unique_question_types = ds[\"train\"].unique(\"question_type\")\n",
    "print(unique_question_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237710e",
   "metadata": {},
   "source": [
    "### Show one example per question type (for verification)\n",
    "\n",
    "This is a quick qualitative check to ensure the dataset fields look as expected for each type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples for each question type:\")\n",
    "\n",
    "for q_type in unique_question_types:\n",
    "    # Filter to the specific question type and select a single example\n",
    "    example = ds[\"train\"].filter(lambda x: x[\"question_type\"] == q_type).select(range(1))\n",
    "\n",
    "    print(f\"\\nQuestion Type: {q_type}\")\n",
    "    print(example[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606a214",
   "metadata": {},
   "source": [
    "### Stratification: keep only MCQ questions + essential columns\n",
    "\n",
    "We:\n",
    "1) Filter the training split to `question_type == \"mcq\"`.\n",
    "2) Keep only the columns needed for fine-tuning / evaluation:\n",
    "   - `question_clean`\n",
    "   - `answer_options`\n",
    "   - `correct_answer`\n",
    "   - `answer_rationale`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543bef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Select only MCQ questions (plus their metadata)\n",
    "mcq_questions = ds[\"train\"].filter(lambda x: x[\"question_type\"] == \"mcq\")\n",
    "\n",
    "# 2) Keep only the columns we need\n",
    "desired_columns = [\"question_clean\", \"answer_options\", \"correct_answer\", \"answer_rationale\"]\n",
    "columns_to_remove = [col for col in mcq_questions.column_names if col not in desired_columns]\n",
    "\n",
    "# Create the pared-down dataset\n",
    "strat_mcq = mcq_questions.remove_columns(columns_to_remove)\n",
    "\n",
    "# Display dataset summary\n",
    "strat_mcq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda8fb7",
   "metadata": {},
   "source": [
    "### Mount Google Drive (for saving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a07f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af95ca",
   "metadata": {},
   "source": [
    "### Helper: detect questions with multiple correct answers\n",
    "\n",
    "Some items have answers like `\"option1, option4\"` or `\"option1 and option3\"`.\n",
    "For MCQ fine-tuning where we only want *single* correct option, we take them out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_multiple_correct_answers(answer: str) -> bool:\n",
    "    \"\"\"Return True if `answer` appears to contain multiple correct options.\n",
    "\n",
    "    Afrimed-QA's `correct_answer` field is typically a string like:\n",
    "    - \"option1\"\n",
    "    - \"option2\"\n",
    "    - \"option1, option4\"\n",
    "    - \"option1 and option3\"\n",
    "\n",
    "    This helper uses simple heuristics (delimiters and repeated 'option' tokens) to detect\n",
    "    multi-answer cases.\n",
    "\n",
    "    Args:\n",
    "        answer: The `correct_answer` field from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        True if the string likely encodes multiple correct answers, otherwise False.\n",
    "    \"\"\"\n",
    "    if isinstance(answer, str):\n",
    "        answer_lower = answer.lower()\n",
    "        return (\n",
    "            (\",\" in answer_lower)\n",
    "            or (\" and \" in answer_lower)\n",
    "            or (answer_lower.count(\"option\") > 1)\n",
    "        )\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff69257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out questions with multiple correct answers\n",
    "strat_mcq_filtered = strat_mcq.filter(lambda x: not has_multiple_correct_answers(x[\"correct_answer\"]))\n",
    "\n",
    "print(f\"Original dataset size: {len(strat_mcq)}\")\n",
    "print(f\"Dataset size after removing multi-answer items: {len(strat_mcq_filtered)}\")\n",
    "\n",
    "# Define the save path on Google Drive\n",
    "save_path = \"/content/drive/MyDrive/AfricaLab/processed_mcq_dataset\"\n",
    "\n",
    "# Save the filtered dataset to Google Drive\n",
    "strat_mcq_filtered.save_to_disk(save_path)\n",
    "\n",
    "print(f\"Dataset saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668009c7",
   "metadata": {},
   "source": [
    "### Quick preview of the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first processed example\n",
    "strat_mcq_filtered[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
